{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1:-\n",
    "\n",
    "Web scraping is the automated process of extracting data from websites using software tools or programs. It involves accessing the HTML code of a webpage and extracting relevant data from it. Web scraping is used to extract data from websites that do not provide a direct way to download or access the data. It is also used to automate data collection from multiple sources, allowing organizations to save time and resources.\n",
    "\n",
    "Three areas where web scraping is used to get data are:\n",
    "\n",
    "Market Research: Web scraping is commonly used in market research to collect data on competitors, pricing, and market trends.\n",
    "\n",
    "Social Media Analysis: Web scraping is used to collect data from social media platforms such as Twitter, Facebook, and LinkedIn. This data can be used for sentiment analysis, social listening, and other purposes.\n",
    "\n",
    "E-commerce: Web scraping is used by e-commerce businesses to collect data on product prices, ratings, and reviews. This data is used to improve pricing strategies, product offerings, and customer engagement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2:-\n",
    "\n",
    "There are several methods used for web scraping, including:\n",
    "\n",
    "Using Web Scraping Tools: There are many web scraping tools available that can extract data from websites. Some of the popular web scraping tools include Scrapy, Beautiful Soup, and Selenium.\n",
    "\n",
    "Writing Custom Code: Developers can write custom code to extract data from websites. This method requires knowledge of web technologies such as HTML, CSS, and JavaScript.\n",
    "\n",
    "API Integration: Some websites provide APIs that allow developers to access data programmatically. This method is preferred when the website provides an API, and the data required is available through the API.\n",
    "\n",
    "Data Mining: Data mining involves using machine learning and statistical techniques to extract data from websites.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3:-\n",
    "\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes. It is a parsing library that can extract data from HTML and XML documents. Beautiful Soup makes it easy to navigate and search HTML and XML documents, making it a popular choice among developers for web scraping.\n",
    "\n",
    "Beautiful Soup is used for web scraping because it can parse and extract data from HTML and XML documents quickly and easily. It provides a simple interface for navigating and searching HTML and XML documents, making it easy to extract the data needed for analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4:-\n",
    "\n",
    "Flask is a lightweight web framework that is used for building web applications in Python. Flask was used in this web scraping project because it provides a simple and flexible framework for building web applications. Flask makes it easy to create a RESTful API that can be used to expose the scraped data to other applications or services. It also provides support for rendering HTML templates, making it easy to build a user interface for the web application."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5:-\n",
    "\n",
    "The AWS Services used in this project are code pipeline and beanstack.\n",
    "\n",
    "AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates. It provides a workflow that enables you to model, visualize, and automate the steps required to release your software. With CodePipeline, you can easily build, test, and deploy your code every time there is a code change, based on your predefined release process.\n",
    "\n",
    "AWS Elastic Beanstalk, on the other hand, is a fully managed service that makes it easy to deploy and run applications in multiple languages, including Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker. Elastic Beanstalk automatically handles the deployment, capacity provisioning, load balancing, and scaling of your application, thereby reducing the complexity of infrastructure management. You simply upload your code, and Elastic Beanstalk handles the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
